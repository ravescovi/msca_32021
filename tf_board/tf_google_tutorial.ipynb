{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, sys, os,shutil\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "##this is important to clean any remaining calls on the system (not sure that is the proper way to explain)\n",
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
      " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
      " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]\n",
      "Num CPU's Available:  1\n",
      "Num GPU's Available:  0\n"
     ]
    }
   ],
   "source": [
    "pprint(tf.config.experimental.list_physical_devices())\n",
    "\n",
    "print(\"Num CPU's Available: \", len(tf.config.experimental.list_physical_devices('CPU')))\n",
    "print(\"Num GPU's Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "if len(tf.config.experimental.list_physical_devices('GPU')):\n",
    "    gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = './logs/'\n",
    "if not os.path.isdir(log_path):\n",
    "    os.mkdir(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create your basic dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create your model\n",
    "def create_basic_model():\n",
    "    my_model =  tf.keras.models.Sequential(\n",
    "        [\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    return my_model\n",
    "\n",
    "def create_basic_model_2(input_shape=None):\n",
    "    my_model =  tf.keras.models.Sequential(\n",
    "        [\n",
    "        Conv2D(16, (3,3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(16, (3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),    \n",
    "        Dense(10, activation='softmax')   \n",
    "        ])\n",
    "    return my_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.2681 - accuracy: 0.1562WARNING:tensorflow:From C:\\Users\\raves\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1875 [..............................] - ETA: 5:25 - loss: 2.2282 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_train_batch_end` time: 0.3422s). Check your callbacks.\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2201 - accuracy: 0.9348 - val_loss: 0.1046 - val_accuracy: 0.9676\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0972 - accuracy: 0.9710 - val_loss: 0.0781 - val_accuracy: 0.9776\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0695 - accuracy: 0.9781 - val_loss: 0.0694 - val_accuracy: 0.9785\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.0626 - val_accuracy: 0.9810\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0429 - accuracy: 0.9858 - val_loss: 0.0659 - val_accuracy: 0.9803\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.0625 - val_accuracy: 0.9819\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0323 - accuracy: 0.9890 - val_loss: 0.0687 - val_accuracy: 0.9831\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.0729 - val_accuracy: 0.9821\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0683 - val_accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0706 - val_accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15ff0132fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = create_basic_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#mac users rejoice\n",
    "#log_dir = os.path.join(log_path,'fit', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "log_dir=\"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 19:09 - loss: 2.1481 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 1.2200s). Check your callbacks.\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.1188 - accuracy: 0.2444\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8292 - accuracy: 0.5007\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5864 - accuracy: 0.6497\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3828 - accuracy: 0.7200\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2151 - accuracy: 0.7582\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 18:50 - loss: 2.2935 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 1.2020s). Check your callbacks.\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.0739 - accuracy: 0.7493\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5588 - accuracy: 0.8591\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4623 - accuracy: 0.8778\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4164 - accuracy: 0.8878\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3869 - accuracy: 0.8936\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 17:26 - loss: 2.2171 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 1.1125s). Check your callbacks.\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2203 - accuracy: 0.9348\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0980 - accuracy: 0.9699\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0700 - accuracy: 0.9784\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0532 - accuracy: 0.9825\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0426 - accuracy: 0.9862\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 17:04 - loss: 2.3193 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 1.0893s). Check your callbacks.\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3112 - accuracy: 0.9121\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1597 - accuracy: 0.9553\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1191 - accuracy: 0.9656\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0957 - accuracy: 0.9730\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9759\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 21:49 - loss: 2.1851 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 1.3917s). Check your callbacks.\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2197 - accuracy: 0.9359\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0951 - accuracy: 0.9708\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0672 - accuracy: 0.9788\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0529 - accuracy: 0.9831\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0417 - accuracy: 0.9862\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 20:26 - loss: 2.5021 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 1.3016s). Check your callbacks.\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2233 - accuracy: 0.9348\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1097 - accuracy: 0.9687\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0858 - accuracy: 0.9764\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0722 - accuracy: 0.9809\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0656 - accuracy: 0.9832\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 16:38 - loss: 2.3457 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 1.0623s). Check your callbacks.\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6449 - accuracy: 0.8329\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3454 - accuracy: 0.9024\n",
      "Epoch 3/5\n",
      "1426/1875 [=====================>........] - ETA: 0s - loss: 0.2941 - accuracy: 0.9174"
     ]
    }
   ],
   "source": [
    "optimizers = [\n",
    "    'Adadelta',\n",
    "    'Adagrad',\n",
    "    'Adam',\n",
    "    'Adamax',\n",
    "    'Nadam',\n",
    "    'RMSprop',\n",
    "    'SGD'\n",
    "]\n",
    "\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    print(optimizer)\n",
    "    model = create_basic_model()\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    log_dir=\"logs\\\\fit\\\\m1\\\\\" + optimizer + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    model.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=32, \n",
    "              epochs=5, \n",
    "              callbacks=[tensorboard_callback])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "lets go on a terminal and actually loot at tensorboard.\n",
    "!tensorboard --logdir logs/fit\n",
    "\n",
    "# More spice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 21:48 - loss: 55.9635 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0089s vs `on_train_batch_end` time: 1.3868s). Check your callbacks.\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 40.1032 - accuracy: 0.1107\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 22.6093 - accuracy: 0.1171\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 15.8241 - accuracy: 0.1574\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 12.2705 - accuracy: 0.2108\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 9.9344 - accuracy: 0.2583\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 17:14 - loss: 85.5622 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 1.0943s). Check your callbacks.\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 6.0583 - accuracy: 0.6458\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 2.2845 - accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 1.7469 - accuracy: 0.8191\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.4754 - accuracy: 0.8391\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.3032 - accuracy: 0.8522\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 18:47 - loss: 37.0221 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0111s vs `on_train_batch_end` time: 1.1918s). Check your callbacks.\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4645 - accuracy: 0.9047\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1119 - accuracy: 0.9661\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0860 - accuracy: 0.9737\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0717 - accuracy: 0.9776\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0638 - accuracy: 0.9808\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 17:56 - loss: 37.7023 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 1.1409s). Check your callbacks.\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.2321 - accuracy: 0.8050\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2087 - accuracy: 0.9422\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1179 - accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0848 - accuracy: 0.9738\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0678 - accuracy: 0.9797\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 24:27 - loss: 53.7603 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0085s vs `on_train_batch_end` time: 1.5588s). Check your callbacks.\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.8086 - accuracy: 0.9007\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1146 - accuracy: 0.9667\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0827 - accuracy: 0.9750\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0689 - accuracy: 0.9784\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0598 - accuracy: 0.9817\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 19:48 - loss: 47.6330 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0086s vs `on_train_batch_end` time: 1.2596s). Check your callbacks.\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.5962 - accuracy: 0.9195\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0937 - accuracy: 0.9745\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0717 - accuracy: 0.9802\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0630 - accuracy: 0.9824\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0596 - accuracy: 0.9841\n",
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 17:03 - loss: 205.8242 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 1.0837s). Check your callbacks.\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 3.0778 - accuracy: 0.1119\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 2.3013 - accuracy: 0.1124\n"
     ]
    }
   ],
   "source": [
    "optimizers = [\n",
    "    'Adadelta',\n",
    "    'Adagrad',\n",
    "    'Adam',\n",
    "    'Adamax',\n",
    "    'Nadam',\n",
    "    'RMSprop',\n",
    "    'SGD'\n",
    "]\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    print(optimizer)\n",
    "    model = create_basic_model_2(input_shape=x_train[0].shape)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    log_dir=\"logs\\\\fit\\\\m2\\\\\" + optimizer + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              batch_size=32, \n",
    "              epochs=5, \n",
    "              callbacks=[tensorboard_callback])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Spice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "batch_size = 32\n",
    "##\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(batch_size)\n",
    "##\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_basic_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "##\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x_train, y_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_train, training=True)\n",
    "        loss = loss_object(y_train, predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y_train, predictions)\n",
    "\n",
    "def test_step(model, x_test, y_test):\n",
    "    predictions = model(x_test)\n",
    "    loss = loss_object(y_test, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs_2\\\\gradient_tape\\\\' + current_time + '\\\\train'\n",
    "test_log_dir = 'logs_2\\\\gradient_tape\\\\' + current_time + '\\\\test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5547308921813965, Accuracy: 91.69999694824219, Test Loss: 1.5141266584396362, Test Accuracy: 94.98999786376953\n",
      "Epoch 2, Loss: 1.5086860656738281, Accuracy: 95.54167175292969, Test Loss: 1.499698281288147, Test Accuracy: 96.45999908447266\n",
      "Epoch 3, Loss: 1.4972286224365234, Accuracy: 96.63166046142578, Test Loss: 1.493033766746521, Test Accuracy: 97.02999877929688\n",
      "Epoch 4, Loss: 1.4912238121032715, Accuracy: 97.11833953857422, Test Loss: 1.490555763244629, Test Accuracy: 97.19000244140625\n",
      "Epoch 5, Loss: 1.4866985082626343, Accuracy: 97.59833526611328, Test Loss: 1.4884986877441406, Test Accuracy: 97.33999633789062\n"
     ]
    }
   ],
   "source": [
    "model = create_basic_model() # reset our model\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (x_train, y_train) in train_ds:\n",
    "        train_step(model, optimizer, x_train, y_train)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    for (x_test, y_test) in test_ds:\n",
    "        test_step(model, x_test, y_test)\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "\n",
    "      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "      print (template.format(epoch+1,\n",
    "                         train_loss.result(), \n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(), \n",
    "                         test_accuracy.result()*100))\n",
    "    # Reset metrics every epoch\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
